# ğŸ¤ í—¤ì´ ì€ì„! v3.0

êµíšŒ ì½”ë¯¸ë””ìš© AI ì„±ê²½ ë´‡ - "í—¤ì´ ì€ì„!"ì´ë¼ê³  ë¶€ë¥´ë©´ ì„±ê²½ êµ¬ì ˆì„ ì½ì–´ì£¼ëŠ” AI

## âœ¨ íŠ¹ì§•

- **STT**: whisper-large-v3-turbo (í•œêµ­ì–´ 95%+ ì •í™•ë„)
- **TTS**: XTTS v2 (ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ë³µì œ)
- **í™”ìì¸ì‹**: SpeechBrain ECAPA-TDNN
- **ì„±ê²½**: ê°œì—­í•œê¸€ 66ê¶Œ ì „ì²´ ì§€ì›
- **GPU**: RTX 4090 ìµœì í™”

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
bible_ai_runpod/
â”œâ”€â”€ server.py              # Runpod ì„œë²„ ì½”ë“œ
â”œâ”€â”€ client.py              # ë¡œì»¬ í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ
â”œâ”€â”€ install.sh             # Runpod ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ start.sh               # ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements_server.txt # ì„œë²„ ì˜ì¡´ì„±
â”œâ”€â”€ requirements_client.txt # í´ë¼ì´ì–¸íŠ¸ ì˜ì¡´ì„±
â””â”€â”€ README.md              # ì´ íŒŒì¼
```

## ğŸš€ Runpod ì„œë²„ ì„¤ì •

### Step 1: Pod ìƒì„±

1. [Runpod](https://runpod.io) ì ‘ì†
2. **Deploy** â†’ **GPU Pod**
3. ì„¤ì •:
   - **GPU**: `RTX 4090` (24GB) - $0.44/hr
   - **Container Disk**: `50GB`
   - **Template**: `RunPod Pytorch 2.4.0`
   - **Expose HTTP Ports**: `8000`

### Step 2: ì„¤ì¹˜

Pod í„°ë¯¸ë„ì—ì„œ:

```bash
cd /app

# GitHubì—ì„œ ì½”ë“œ ë‹¤ìš´ë¡œë“œ
git clone https://github.com/cosmosapjw-quantum/eunseok_AI.git
cd eunseok_AI/eunseok_AI/bible_ai_runpod

# ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x install.sh
./install.sh
```

### Step 3: ìŒì„± íŒŒì¼ ë³µì‚¬

```bash
# ìŒì„± íŒŒì¼ì„ voice_samples í´ë”ë¡œ ë³µì‚¬
cp /app/eunseok_AI/eunseok_AI/*.m4a /app/voice_samples/
cp /app/eunseok_AI/eunseok_AI/*.mp3 /app/voice_samples/

# WAV ë³€í™˜ (TTS ì°¸ì¡°ìš©)
ffmpeg -i /app/voice_samples/insuk.m4a /app/voice_samples/insuk.wav
```

### Step 4: ì„œë²„ ì‹¤í–‰

```bash
cd /app
./start.sh
```

ì˜ˆìƒ ì¶œë ¥:
```
============================================================
  ğŸ¤ í—¤ì´ ì€ì„! v3.0
  ğŸ“Š STT: whisper-large-v3-turbo
  ğŸ”Š TTS: XTTS v2
============================================================

[GPU] NVIDIA GeForce RTX 4090 (24.0GB)
[MODEL] Whisper ë¡œë”©: large-v3-turbo
[MODEL] Whisper ë¡œë“œ ì™„ë£Œ!
[MODEL] í™”ì ì¸ì‹ ëª¨ë¸ ë¡œë”©...
  âœ“ jiwon: me.mp3
  âœ“ moksa: moksa.mp3
[MODEL] XTTS v2 ë¡œë”©...
  âœ“ ì°¸ì¡° ìŒì„±: insuk.wav
[MODEL] XTTS ë¡œë“œ ì™„ë£Œ!
[DATA] ì„±ê²½ ë¡œë”©: /app/bible_ko.json
[DATA] 66ê¶Œ ë¡œë“œ

============================================================
  âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!
  ğŸ“– ì„±ê²½: 66ê¶Œ
  ğŸ‘¥ í™”ì: 2ëª…
  ğŸ™ï¸ TTS: ì¤€ë¹„ë¨
============================================================

INFO:     Uvicorn running on http://0.0.0.0:8000
```

### Step 5: ì„œë²„ URL í™•ì¸

Runpod ëŒ€ì‹œë³´ë“œì—ì„œ:
1. Pod í´ë¦­
2. **Connect** ë²„íŠ¼
3. **HTTP Service [Port 8000]** URL ë³µì‚¬

URL í˜•ì‹: `https://[POD-ID]-8000.proxy.runpod.net`

---

## ğŸ’» ë¡œì»¬ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •

### Step 1: ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install requests sounddevice soundfile numpy
```

macOSì˜ ê²½ìš°:
```bash
brew install portaudio
pip install pyaudio
```

### Step 2: í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰

```bash
python client.py --server https://YOUR-POD-ID-8000.proxy.runpod.net
```

### ì‚¬ìš©ë²•

1. í”„ë¡œê·¸ë¨ì´ ì‹œì‘ë˜ë©´ **"í—¤ì´ ì€ì„!"**ì´ë¼ê³  ë§í•©ë‹ˆë‹¤
2. ì¸ì‚¬ë§ì´ ë‚˜ì˜¤ë©´ **ì„±ê²½ êµ¬ì ˆ**ì„ ë§í•©ë‹ˆë‹¤
   - ì˜ˆ: "ìš”í•œë³µìŒ 3ì¥ 16ì ˆ"
   - ì˜ˆ: "ì°½ì„¸ê¸° 1ì¥ 1ì ˆ"
   - ì˜ˆ: "ì‹œí¸ 23í¸ 1ì ˆ"
3. AIê°€ í•´ë‹¹ êµ¬ì ˆì„ ì½ì–´ì¤ë‹ˆë‹¤

---

## ğŸ”§ API ì—”ë“œí¬ì¸íŠ¸

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/` | GET | ì„œë²„ ì •ë³´ |
| `/health` | GET | ìƒíƒœ í™•ì¸ |
| `/voices` | GET | ìŒì„± íŒŒì¼ ëª©ë¡ |
| `/upload` | POST | ìŒì„± íŒŒì¼ ì—…ë¡œë“œ |
| `/process_wake` | POST | ì›¨ì´í¬ì›Œë“œ ì²˜ë¦¬ |
| `/process_bible` | POST | ì„±ê²½ êµ¬ì ˆ ì²˜ë¦¬ |
| `/tts` | POST | í…ìŠ¤íŠ¸ â†’ ìŒì„± |
| `/test` | GET | êµ¬ì ˆ í…ŒìŠ¤íŠ¸ |
| `/reload` | POST | ìŒì„± ë¦¬ë¡œë“œ |

### í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```bash
# ì„œë²„ ìƒíƒœ í™•ì¸
curl https://YOUR-URL/health

# ì„±ê²½ êµ¬ì ˆ í…ŒìŠ¤íŠ¸
curl "https://YOUR-URL/test?book=ìš”í•œë³µìŒ&chapter=3&verse=16"
```

---

## ğŸ“‚ ìŒì„± íŒŒì¼

### í•„ìš”í•œ íŒŒì¼

| íŒŒì¼ëª… | ìš©ë„ | í•„ìˆ˜ |
|--------|------|------|
| `insuk.wav` | TTS ì°¸ì¡° ìŒì„± (ì€ì„ ëª©ì†Œë¦¬) | â­• |
| `me.mp3` | ì§€ì› í™”ì ì¸ì‹ìš© | âŒ |
| `moksa.mp3` | ëª©ì‚¬ë‹˜ í™”ì ì¸ì‹ìš© | âŒ |
| `hyanguk.mp3` | í–¥ìš± í™”ì ì¸ì‹ìš© | âŒ |

### WAV ë³€í™˜

```bash
# m4a â†’ wav
ffmpeg -i insuk.m4a insuk.wav

# mp3 â†’ wav
ffmpeg -i insuk.mp3 insuk.wav
```

---

## âš™ï¸ ì„¤ì • ë³€ê²½

`server.py`ì˜ `Config` í´ë˜ìŠ¤ì—ì„œ:

```python
@dataclass
class Config:
    # STT ëª¨ë¸ (large-v3-turbo ê¶Œì¥)
    whisper_model: str = "large-v3-turbo"
    
    # í™”ìì¸ì‹ ì„ê³„ê°’ (0.0~1.0, ë‚®ì„ìˆ˜ë¡ ê´€ëŒ€)
    speaker_threshold: float = 0.18
    
    # TTS ì–¸ì–´
    tts_language: str = "ko"
```

### Whisper ëª¨ë¸ ì˜µì…˜

| ëª¨ë¸ | VRAM | ì†ë„ | ì •í™•ë„ |
|------|------|------|--------|
| `small` | 2GB | âš¡âš¡âš¡ | â­â­ |
| `medium` | 5GB | âš¡âš¡ | â­â­â­ |
| `large-v3-turbo` | 6GB | âš¡âš¡ | â­â­â­â­ |
| `large-v3` | 10GB | âš¡ | â­â­â­â­â­ |

---

## ğŸ› ë¬¸ì œ í•´ê²°

### cuDNN ì˜¤ë¥˜

```
Unable to load libcudnn_ops.so.9.1.0
```

í•´ê²°:
```bash
export LD_LIBRARY_PATH=/usr/local/lib/python3.11/dist-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH
```

ë˜ëŠ” `./start.sh` ì‚¬ìš©

### ìŒì„± íŒŒì¼ ì¸ì‹ ì•ˆë¨

```bash
# íŒŒì¼ í™•ì¸
ls -la /app/voice_samples/

# ë¦¬ë¡œë“œ
curl -X POST https://YOUR-URL/reload
```

### STT ì •í™•ë„ ë‚®ìŒ

1. ë§ˆì´í¬ í’ˆì§ˆ í™•ì¸
2. ì¡°ìš©í•œ í™˜ê²½ì—ì„œ ë…¹ìŒ
3. ì²œì²œíˆ ë˜ë°•ë˜ë°• ë§í•˜ê¸°

---

## ğŸ“Š ì„±ëŠ¥

RTX 4090 ê¸°ì¤€:

| í•­ëª© | ì‹œê°„ |
|------|------|
| STT (3ì´ˆ ì˜¤ë””ì˜¤) | 0.3~0.5ì´ˆ |
| TTS (ì§§ì€ ë¬¸ì¥) | 2~3ì´ˆ |
| TTS (ê¸´ êµ¬ì ˆ) | 5~8ì´ˆ |

---

## ğŸ“œ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ™ ê°ì‚¬

- [faster-whisper](https://github.com/SYSTRAN/faster-whisper)
- [Coqui TTS](https://github.com/coqui-ai/TTS)
- [SpeechBrain](https://github.com/speechbrain/speechbrain)
- ì„±ê²½ ë°ì´í„°: [thiagobodruk/bible](https://github.com/thiagobodruk/bible)
